{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faf0789b-c82a-4a3f-8447-a8ced1dfce43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### How would you handle null values in a DataFrame? For example, drop rows with null values in the age column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c66bd83-fb24-46fe-ab59-804039918f4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n|  Name| Age|\n+------+----+\n|Rohish|  30|\n|  Ajit|null|\n|Rajani|  25|\n|  null|  35|\n|   Eve|null|\n+------+----+\n\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "data = [\n",
    "    (\"Rohish\", 30),\n",
    "    (\"Ajit\", None),\n",
    "    (\"Rajani\", 25),\n",
    "    (None, 35),\n",
    "    (\"Eve\", None)\n",
    "]\n",
    "\n",
    "columns = [\"Name\", \"Age\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a4a429f-3b80-407f-8a3c-b534cfaa5d72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**How would you handle null values in a DataFrame?**\n",
    "- [click here to read more](https://github.com/rohish-zade/PySpark/blob/main/dataFrame_API/15_handling_null_values_in_pyspark.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2797fb0d-0cc9-4371-bb17-2676b94bb0b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**drop rows with null values in the age column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c9d6613-31f9-45da-b0ef-a0bba80b459b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n|Name| Age|\n+----+----+\n|Ajit|null|\n| Eve|null|\n+----+----+\n\n"
     ]
    }
   ],
   "source": [
    "# rows with null values in the Age column\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.filter(col(\"Age\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a82611d7-f1f9-4887-b7b7-c5c2e5bf78a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n|  Name|Age|\n+------+---+\n|Rohish| 30|\n|Rajani| 25|\n|  null| 35|\n+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# lets drop these rows with null values in the Age column\n",
    "\n",
    "# To drop rows where the age column has null values in PySpark, use the dropna() function with the subset parameter:\n",
    "cleaned_df = df.dropna(subset=[\"Age\"])\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd0095c-8caf-4aa1-8589-1e894468bf70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n|  Name|Age|\n+------+---+\n|Rohish| 30|\n|Rajani| 25|\n|  null| 35|\n+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# alternative approch: Using filter() or where()\n",
    "\n",
    "cleaned_df_2 = df.filter(col(\"Age\").isNotNull())\n",
    "cleaned_df_2.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "question_5",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
