{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb0a589b-9de1-425e-aca0-6ec4006af57a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating a new column in Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3a1ecbe-04f6-4de4-9b7c-deb14a0c4950",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "How you can create a new column derived from existing columns in a PySpark DataFrame in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fed6d9c-e2bb-41f7-bbcb-d5d9ac8482fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n|  Name|Age|Salary|\n+------+---+------+\n|Rohish| 34|  5000|\n|  Smit| 45|  4000|\n|Pushak| 23|  3000|\n|Faisal| 37|  7000|\n+------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "data = [\n",
    "    (\"Rohish\", 34, 5000),\n",
    "    (\"Smit\", 45, 4000),\n",
    "    (\"Pushak\", 23, 3000),\n",
    "    (\"Faisal\", 37, 7000)\n",
    "]\n",
    "\n",
    "columns = [\"Name\", \"Age\", \"Salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8428956c-239b-432b-8616-c6961c3d7452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e99f73e-0dec-439d-b0e5-b535a50bd3fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Coding Question 1:** Creating a New Column Using Arithmetic Operations. \n",
    "\n",
    "Create a new column Bonus which is 10% of the Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02c350bb-16f6-4a22-aca8-ca07bea9b552",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+-----+\n|  Name|Age|Salary|Bonus|\n+------+---+------+-----+\n|Rohish| 34|  5000|  500|\n|  Smit| 45|  4000|  400|\n|Pushak| 23|  3000|  300|\n|Faisal| 37|  7000|  700|\n+------+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df1 = df.withColumn(\"Bonus\", (col(\"salary\")* 0.10).cast(\"long\"))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c55e90e-78c0-4a89-88ae-a567ce37f16c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e74b93fe-d947-4cd4-98ab-3b2040808d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Coding Question 2:** Creating a New Column Using Conditional Statements\n",
    "\n",
    "Create a new column Category that categorizes people based on their age:\n",
    "- If age is less than 30, the category is Young.\n",
    "- If age is between 30 and 40, the category is Mid-age.\n",
    "- If age is greater than 40, the category is Senior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5097cc73-f3c5-4f9e-b478-35c234ada237",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+--------+\n|  Name|Age|Salary|Category|\n+------+---+------+--------+\n|Rohish| 34|  5000| Mid-Age|\n|  Smit| 45|  4000|  Senior|\n|Pushak| 23|  3000|   Young|\n|Faisal| 37|  7000| Mid-Age|\n+------+---+------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df3 = df.withColumn(\"Category\", when(col(\"Age\") < 30, \"Young\") \\\n",
    "                                .when((col(\"Age\") >= 30) & (col(\"Age\") <= 40), \"Mid-Age\") \\\n",
    "                                .otherwise(\"Senior\")\n",
    "            )\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70ea8056-f620-4e59-8aa4-f74df8968de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b8ad0dc-0ac8-47ce-a80d-ad4070ee154b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Coding Question 3:** Creating a New Column by Combining Two Columns\n",
    "\n",
    "Create a new column `Full Info` that combines Name and Age into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d287450-d9ee-4e85-8225-4308903f8639",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+----------------------+\n|Name  |Age|Salary|Full Info             |\n+------+---+------+----------------------+\n|Rohish|34 |5000  |Rohish is 34 years old|\n|Smit  |45 |4000  |Smit is 45 years old  |\n|Pushak|23 |3000  |Pushak is 23 years old|\n|Faisal|37 |7000  |Faisal is 37 years old|\n+------+---+------+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, lit\n",
    "\n",
    "df4 = df.withColumn(\"Full Info\", concat(col(\"Name\"), lit(\" is \"), col(\"Age\"), lit(\" years old\")))\n",
    "df4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e226548b-b3b8-4162-adb0-08c0d90baee5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32308886-279f-42a3-855b-b2d1083decb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Coding Question 4:** Creating a New Column Using a UDF (User-Defined Function)\n",
    "\n",
    "Define a UDF to classify the salary range:\n",
    "- Low if salary is less than 4000.\n",
    "- Medium if salary is between 4000 and 6000.\n",
    "- High if salary is greater than 6000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d46e631b-608e-47d3-b8f7-47278f7be41e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+---------------+\n|  Name|Age|Salary|salary category|\n+------+---+------+---------------+\n|Rohish| 34|  5000|         Medium|\n|  Smit| 45|  4000|         Medium|\n|Pushak| 23|  3000|            Low|\n|Faisal| 37|  7000|           High|\n+------+---+------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def classify_salary(salary):\n",
    "    if salary < 4000:\n",
    "        return \"Low\"\n",
    "    elif salary >= 4000 and salary <= 6000:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "# Register UDF to use in DataFrame API\n",
    "salary_udf = udf(classify_salary, StringType())\n",
    "\n",
    "df5 = df.withColumn(\"salary category\", salary_udf(col(\"Salary\")))\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2af8b1bc-43a9-4b92-b1b2-7eeb47f10f5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aadede47-0df1-421a-9172-0b111c3defeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Coding Question 5:** Creating a New Column Using SQL Expressions\n",
    "\n",
    "Use Spark SQL to create a new column Net Salary where Net Salary = Salary + Bonus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "754b8222-3fc4-44ec-884a-8794fa633cb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+-----+----------+\n|  Name|Age|Salary|Bonus|Net Salary|\n+------+---+------+-----+----------+\n|Rohish| 34|  5000|  500|      5500|\n|  Smit| 45|  4000|  400|      4400|\n|Pushak| 23|  3000|  300|      3300|\n|Faisal| 37|  7000|  700|      7700|\n+------+---+------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# create a view first\n",
    "df.createOrReplaceTempView(\"emp_tbl\")\n",
    "\n",
    "df6 = spark.sql(\"\"\"select *, cast((Salary * 0.10) as long) as Bonus, \n",
    "                cast((Salary + (Salary * 0.10)) as long) as `Net Salary` \n",
    "                from emp_tbl;\n",
    "        \"\"\")\n",
    "df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ce26924-a7c7-413c-8a58-c25e0b8e0567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Name</th><th>Age</th><th>Salary</th><th>Net Salary</th></tr></thead><tbody><tr><td>Rohish</td><td>34</td><td>5000</td><td>5500.00</td></tr><tr><td>Smit</td><td>45</td><td>4000</td><td>4400.00</td></tr><tr><td>Pushak</td><td>23</td><td>3000</td><td>3300.00</td></tr><tr><td>Faisal</td><td>37</td><td>7000</td><td>7700.00</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Rohish",
         34,
         5000,
         "5500.00"
        ],
        [
         "Smit",
         45,
         4000,
         "4400.00"
        ],
        [
         "Pushak",
         23,
         3000,
         "3300.00"
        ],
        [
         "Faisal",
         37,
         7000,
         "7700.00"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Net Salary",
         "type": "\"decimal(24,2)\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select *, (Salary + (Salary * 0.10)) as `Net Salary` from emp_tbl;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1369752488845892,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "question_12_creating_new_column",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}