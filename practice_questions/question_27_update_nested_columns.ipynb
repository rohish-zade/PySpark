{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc60f581-9d40-4cd7-b4d5-d06869b758a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### How to Update Nested Columns in PySpark Dataframe?\n",
    "\n",
    "- In PySpark, updating nested columns (such as updating fields within a struct) can be done using the withColumn function, combined with functions like col, struct, and alias.\n",
    "- This is especially useful when you're dealing with JSONlike structures or deeply nested data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d98fd9f-c13c-47b1-a4d9-b00612d5c34e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Sample data:**\n",
    "\n",
    "Suppose we have a DataFrame representing employees with nested columns that store personal information in a struct format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13a2ec8a-b231-42b0-a080-8096ee07e2da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------------+---+\n|Name|PersonalInfo                       |Age|\n+----+-----------------------------------+---+\n|John|{john.doe@example.com, New York}   |30 |\n|Jane|{jane.doe@example.com, Los Angeles}|28 |\n+----+-----------------------------------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = [\n",
    "    (\"John\", (\"john.doe@example.com\", \"New York\"), 30),\n",
    "    (\"Jane\", (\"jane.doe@example.com\", \"Los Angeles\"), 28)\n",
    "]\n",
    "\n",
    "# Define schema\n",
    "columns = [\"Name\", \"PersonalInfo\", \"Age\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Here, the PersonalInfo column is a struct containing two fields: Email and City."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c0d32ab-b497-455f-aeca-8367b18afae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Coding Task: Update Nested Column**\n",
    "\n",
    "Suppose you want to update the City field inside the PersonalInfo struct for each employee, and change \"New York\" to \"Boston\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6d6fca7-2088-4dd1-85c9-4031629f7281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Solution: Use withColumn and col**\n",
    "1. First, we will extract the individual fields from the struct.\n",
    "2. Then, we'll update the required field (City in this case).\n",
    "3. Finally, we'll reconstruct the struct with the updated field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57aa5b5c-a28c-4fe4-92cf-bfef679057a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------------+---+\n|Name|PersonalInfo                       |Age|\n+----+-----------------------------------+---+\n|John|{john.doe@example.com, Boston}     |30 |\n|Jane|{jane.doe@example.com, Los Angeles}|28 |\n+----+-----------------------------------+---+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Update the City field inside the PersonalInfo struct\n",
    "updated_df = df.withColumn(\"PersonalInfo\",\n",
    "                            struct(\n",
    "                                col(\"PersonalInfo._1\").alias(\"Email\"),\n",
    "                                when(col(\"PersonalInfo._2\") == \"New York\", \"Boston\") \\\n",
    "                                .otherwise(col(\"PersonalInfo._2\")).alias(\"City\")\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "updated_df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "question_27_update_nested_columns",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}