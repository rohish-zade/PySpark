{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93edf27d-652c-44d5-9239-0ed3d4406ba3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Pattern Matching in PySpark\n",
    "\n",
    "Pattern matching in PySpark refers to several techniques for filtering and selecting data based on pattern conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "519b3129-65cb-400f-97cf-09e2faf317e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22837a7d-1b5b-46f5-8abe-2408ad8a486f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+------+\n|EmployeeID|         Name|Department|Salary|\n+----------+-------------+----------+------+\n|         1|       Rohish|        HR|  5000|\n|         2|         Smit|        HR|  6000|\n|         3|       Faisal|        IT|  7000|\n|         4|      Pushpak|        IT|  9000|\n|         5|      Rishabh|        HR|  5500|\n|         6|        Vinit|        IT|  8000|\n|         7|DemonSlayer69|        IT| 10000|\n+----------+-------------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "data = [\n",
    "    (1, 'Rohish', 'HR', 5000),\n",
    "    (2, 'Smit', 'HR', 6000),\n",
    "    (3, 'Faisal', 'IT', 7000),\n",
    "    (4, 'Pushpak', 'IT', 9000),\n",
    "    (5, 'Rishabh', 'HR', 5500),\n",
    "    (6, 'Vinit', 'IT', 8000),\n",
    "    (7, 'DemonSlayer69', 'IT', '10000')\n",
    "]\n",
    "\n",
    "columns = [\"EmployeeID\", \"Name\", \"Department\", \"Salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "569fadd2-18d9-4fb1-8eb6-b47a6dc5f454",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Using `like()` for SQL-style Pattern Matching\n",
    "\n",
    "Works like SQL's LIKE, supporting `%` (wildcard for multiple characters) and `_` (wildcard for a single character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63d5b2ab-7700-4f47-aeae-d9bdf3bf28fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+------+\n|EmployeeID|   Name|Department|Salary|\n+----------+-------+----------+------+\n|         1| Rohish|        HR|  5000|\n|         5|Rishabh|        HR|  5500|\n+----------+-------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Find names starting with 'R'\n",
    "df.filter(col(\"Name\").like(\"R%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e03f7095-10ae-4d9d-a586-157629689e7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----------+------+\n|EmployeeID|Name|Department|Salary|\n+----------+----+----------+------+\n+----------+----+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Find names starting with 'R'\n",
    "df.filter(col(\"Name\").like(\"%R\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2db9322a-276d-4376-b546-793b939cbc33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+------+\n|EmployeeID|   Name|Department|Salary|\n+----------+-------+----------+------+\n|         1| Rohish|        HR|  5000|\n|         4|Pushpak|        IT|  9000|\n|         5|Rishabh|        HR|  5500|\n+----------+-------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter names containing \"sh\"\n",
    "df.filter(col(\"Name\").like(\"%sh%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd072ab9-d9bb-4cb9-ac48-0f99a304ccf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+------+\n|EmployeeID|  Name|Department|Salary|\n+----------+------+----------+------+\n|         1|Rohish|        HR|  5000|\n+----------+------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter names with 6 letters, starting with \"A\"\n",
    "df.filter(col(\"Name\").like(\"R_____\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37d48016-12fd-47f4-bf8b-d381de33a72e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7c12e30-093d-4c85-8656-afbe1c353cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Using `rlike()` for Regular Expression Matching\n",
    "\n",
    "The rlike function allows you to use regular expressions for more complex pattern matching.\n",
    "- `.` in regex: Matches any single character\n",
    "- `*` in regex: Matches zero or more of the preceding element\n",
    "- `+` in regex: Matches one or more of the preceding element\n",
    "- `^` in regex: Matches the start of the string\n",
    "- `$` in regex: Matches the end of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1e38a65-49bb-45b7-8f98-5f71ba745c52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+------+\n|EmployeeID|   Name|Department|Salary|\n+----------+-------+----------+------+\n|         1| Rohish|        HR|  5000|\n|         5|Rishabh|        HR|  5500|\n+----------+-------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter names starting with \"R\" (using regex)\n",
    "df.filter(col(\"Name\").rlike(\"^R\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "082103fd-686d-4494-8ee7-0500be8ec3f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+------+\n|EmployeeID|   Name|Department|Salary|\n+----------+-------+----------+------+\n|         1| Rohish|        HR|  5000|\n|         5|Rishabh|        HR|  5500|\n+----------+-------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter names ending with \"h\"\n",
    "df.filter(col(\"Name\").rlike(\"h$\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc4ca375-e9f6-41a4-8db3-7e6c7c699fc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+------+\n|EmployeeID|         Name|Department|Salary|\n+----------+-------------+----------+------+\n|         7|DemonSlayer69|        IT| 10000|\n+----------+-------------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter names containing numbers\n",
    "df.filter(col(\"name\").rlike(\"[0-9]\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5cf7056-1e79-4e03-9aa1-eb9eb7f9e14b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Using `regexp_like` Function (Regular Expressions, Spark 3.0+)\n",
    "\n",
    "`regexp_like` is available in Spark 3.0 and later versions. It is similar to rlike but is more aligned with standard SQL regular expression syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4298f9f0-b8e5-4615-93a1-439ecc55240b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2921023638831196>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m # Filter names starting with \"F\" (using regex)\n",
       "\u001B[1;32m      2\u001B[0m df.filter(regexp_like(col(\"name\"), \"^F\")).show()\n",
       "\n",
       "\u001B[0;31mImportError\u001B[0m: cannot import name 'regexp_like' from 'pyspark.sql.functions' (/databricks/spark/python/pyspark/sql/functions.py)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)\nFile \u001B[0;32m<command-2921023638831196>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m # Filter names starting with \"F\" (using regex)\n\u001B[1;32m      2\u001B[0m df.filter(regexp_like(col(\"name\"), \"^F\")).show()\n\n\u001B[0;31mImportError\u001B[0m: cannot import name 'regexp_like' from 'pyspark.sql.functions' (/databricks/spark/python/pyspark/sql/functions.py)",
       "errorSummary": "<span class='ansi-red-fg'>ImportError</span>: cannot import name 'regexp_like' from 'pyspark.sql.functions' (/databricks/spark/python/pyspark/sql/functions.py)",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_like\n",
    "\n",
    "# Filter names starting with \"F\" (using regex)\n",
    "df.filter(regexp_like(col(\"Name\"), \"^F\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41ecdfba-14ec-4dd9-bab5-4939af8aa6da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### NOTE: rlike() is PySpark's equivalent of SQL’s regexp_like() if its not availabe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13f08e4f-c391-4adf-8de4-f7664f0c430d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80490d01-6057-4938-800c-221e78670ab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Using `contains()` for Substring Matching\n",
    "\n",
    "To check if a column contains a substring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "654ff699-baad-4ae4-81bf-3001ca687c4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+------+\n|EmployeeID|   Name|Department|Salary|\n+----------+-------+----------+------+\n|         1| Rohish|        HR|  5000|\n|         5|Rishabh|        HR|  5500|\n+----------+-------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Find names containing 'ish'\n",
    "df.filter(col(\"Name\").contains(\"ish\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc521d48-aa13-42ed-9e9c-edcd46ab426b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc0b564e-e606-4254-92fa-13d183e338e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Using `startswith()` and `endswith()`\n",
    "\n",
    "If you only need to filter based on a prefix or suffix, these functions are more efficient than `like()` or `rlike().`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b43e90bd-3208-4294-9297-3a914b52ab9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+------+\n|EmployeeID|         Name|Department|Salary|\n+----------+-------------+----------+------+\n|         7|DemonSlayer69|        IT| 10000|\n+----------+-------------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Names starting with 'D'\n",
    "df.filter(col(\"Name\").startswith(\"D\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "221fc404-395c-471a-a202-f83a46a6db70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+------+\n|EmployeeID|   Name|Department|Salary|\n+----------+-------+----------+------+\n|         1| Rohish|        HR|  5000|\n|         5|Rishabh|        HR|  5500|\n+----------+-------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Names ending with 'h'\n",
    "df.filter(col(\"Name\").endswith(\"h\")).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "16_pattern_matching_in_pyspark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}