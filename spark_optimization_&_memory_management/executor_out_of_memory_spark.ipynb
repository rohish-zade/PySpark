{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec6dbb15-0aca-48e6-99fc-c64506cf12d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Executor Memory in Spark\n",
    "The executor memory in Spark refers to the memory allocated to each executor process. Executors are responsible for running tasks and storing intermediate data. \n",
    "\n",
    "Spark uses a unified memory management model that handles both execution and storage memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6007e3bd-61b7-4c06-8c85-8b92010a1f8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Potential Interview Questions:**\n",
    "\n",
    "- Why do we get OOM when data can be spilled to the disk?\n",
    "- How Spark manages storage inside executor internally?\n",
    "- How task is split in executor?\n",
    "- Why do we need overhead memory?\n",
    "- When do we get executor OOM?\n",
    "- Types of memory manager in Spark?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "008bfcb5-8561-4627-b641-abfcf3b8319c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "398e1b23-852e-43de-be6a-eb871730015d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Components of Executor Memory\n",
    "The total memory allocated to an executor (`spark.executor.memory`) is divided into` heap memory` and `overhead memory.`\n",
    "\n",
    "- **JVM Heap Memory:** The main memory for data processing and storage (divided into execution and storage memory).\n",
    "- **Off-Heap:** Memory\tMemory for unmanaged storage (e.g., Tungsten optimizations).\n",
    "- **Overhead Memory:** Additional memory for JVM processes, including shuffle buffers and garbage collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e14dc6eb-970c-4b5a-bf53-342f20ba6d6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/rohish-zade/PySpark/refs/heads/main/materials/spark-executor-memory.png\" alt=\"spark-executor-memory\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43608ad3-cb33-437a-9308-92559a4e04f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![imag](https://raw.githubusercontent.com/rohish-zade/PySpark/refs/heads/main/materials/spark-executor-memory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5149a349-7145-4440-b5ab-9c6d7d0cdc67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Overhead Memory\n",
    "- It is used for non-JVM processes. \n",
    "- controlled by the `spark.executor.memoryOverhead` parameter.\n",
    "- JVM overhead for garbage collection.\n",
    "- Memory for shuffle operations and buffering.\n",
    "- Native memory for off-heap operations.\n",
    "- Spark internal processes (e.g., task dispatching).\n",
    "- Default value: max(10% of `spark.executor.memory`, 384 MB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f841e4ed-d0d6-4874-83fd-e743fff77e64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af53bb5f-f153-4be5-9e6d-59cdc2a51df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### JVM Heap Memory\n",
    "This is the main part of the executor memory, controlled by the `spark.executor.memory` parameter.\n",
    "\n",
    "It is further divided into two areas:\n",
    "- **Reserved Memory**\n",
    "- **User Memory:**\n",
    "- **Spark Memory:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fe90ec6-556d-4f0f-97fe-3e6d34aed9ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Reserved Memory\n",
    "- To ensure Spark’s internal operations (e.g., monitoring, bookkeeping, and maintaining metadata) have sufficient memory to function even under heavy workloads.\n",
    "- It is used to stored the spark internal objects.\n",
    "- used by spark engine\n",
    "- It is not available for either execution or storage tasks.\n",
    "- `Default Value:` Spark reserves 300 MB of memory by default for this purpose, which cannot be reconfigured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33e13598-a520-4690-b42d-f20f0a4b5a0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### User Memory\n",
    "25% of the allocated executor memory used for:\n",
    "- Remaining heap memory outside Spark's managed memory\n",
    "- Stores the data structures and used defined functions\n",
    "- Metadata and data structures related to RDD partitions, Spark SQL structures, third-party libraries, and broadcast variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2402c1ad-258a-49b5-98cb-2bee72b94f06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Spark Memory\n",
    "\n",
    "Spark uses a unified memory model, which means the execution and storage memory share the same pool.\n",
    "Unused storage memory can be borrowed by execution tasks and vice versa.\n",
    "\n",
    "75% of the allocated executor memory, further divided into:\n",
    "- **Execution Memory:** \n",
    "  - Used for shuffle, join, and sort operations. It spills to disk if memory limits are exceeded.\n",
    "  - Execution memory is used for storing temporary data structures during task execution.\n",
    "  - It's used for storing serialized task results, intermediate data, and shuffle data. \n",
    "  - If Storage Memory isn't fully utilized, unused memory can be borrowed for Execution Memory.\n",
    "\n",
    "- **Storage Memory:** \n",
    "  - Used for caching RDDs, DataFrames, and broadcast variables. Can spill to disk if necessary.\n",
    "  - Storage memory is used for caching RDDs, DataFrames, and Datasets. \n",
    "  - It's managed by the Memory Manager and takes up a portion of the heap and off-heap memory. \n",
    "  - The LRU `(Least Recently Used`) algorithm is used to evict cached data from storage memory when it's full.\n",
    "  - Purpose:\n",
    "    - To avoid recomputation of frequently accessed data.\n",
    "    - To reduce I/O overhead by caching data in memory instead of reading it repeatedly from disk.\n",
    "  - Configuration:\n",
    "    - The size of storage memory is dynamically adjusted within the Spark Memory pool based on workload needs.\n",
    "    - Example: If execution memory requires more space, it can borrow from the storage memory pool.\n",
    "\n",
    "The boundary between execution and storage memory is flexible, allowing Spark to allocate memory dynamically based on current needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5318dcd6-f583-42f2-ae79-a557d50b5269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8cc5c6a-c6ff-41ce-beca-dbd6186b150f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Why do we get executor OOM(Out of Memory) when data can be spilled to the disk?\n",
    "\n",
    "- Executor OOM occurs because spilling to disk still requires memory for buffering and organizing data (e.g., for shuffle or sort operations) before the spill happens. \n",
    "- If the memory needed for this preparation exceeds the available memory, OOM occurs even before spilling starts.\n",
    "- If the executor doesn’t have enough memory to handle these intermediate operations or if tasks process very large data due to improper partitioning or skew, the executor can run out of memory. Additionally, insufficient overhead memory for tasks and slow disk I/O can exacerbate the issue.\n",
    "\n",
    "##### below can be the number of reasons for executor OOM(Out of Memory):\n",
    "- **Insufficient Memory for Spill Preparation:** Before spilling data to disk, Spark organizes and buffers it in memory. If memory is too constrained, even temporary buffering fails.\n",
    "- **Large Shuffle or Aggregation Operations:** When shuffle or aggregation results exceed the allocated memory and the spill process cannot keep up, OOM can occur.\n",
    "- **Improper Memory Allocation:**\n",
    "  - Insufficient memory for the task (executor memory too small).\n",
    "  - Poor tuning of memory fractions (e.g., spark.memory.fraction).\n",
    "- **Large Broadcast Variables:** If broadcast variables or dataframes are too large to fit into available memory.\n",
    "- **Memory Leaks:** Accumulation of references in RDDs or DataFrames can prevent garbage collection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbf52908-5c94-46f0-8989-13257974093d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fd4ad7a-a8ff-449a-a869-45eefb321f71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. How Spark manages storage inside an executor internally?\n",
    "Inside each executor, Spark divides memory into distinct areas:\n",
    "\n",
    "**a) Unified Memory Management (default in Spark 1.6+):**\n",
    "- Execution Memory: For computations like shuffles, joins, sorts, and aggregations.\n",
    "- Storage Memory: For caching RDDs and DataFrames.\n",
    "- Both share the same memory pool, which can dynamically adjust:\n",
    "  - If execution memory demands increase, it can take from storage memory (if unoccupied).\n",
    "  - Similarly, storage memory can expand into unused execution memory.\n",
    "\n",
    "**b) Heap Memory Breakdown:**\n",
    "- Executor Memory: Divided into:\n",
    "  - User Memory: Available for user-defined objects.\n",
    "  - Reserved Memory: Fixed memory Spark reserves for internal needs.\n",
    "  - Spark Memory: \n",
    "    - Execution (task-specific computations).\n",
    "    - Storage (caching/persistence).\n",
    "\n",
    "**c) Disk Spill Mechanism:**\n",
    "- When memory is insufficient, Spark spills intermediate data to disk.\n",
    "- Spill occurs in stages (e.g., during shuffle, sort, or join operations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6956903d-05e4-4113-8382-d7b7b6b8b04e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61433b93-789a-4eda-8a6e-596277c94288",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Why do we need overhead memory?\n",
    "Overhead memory is reserved for non-heap usage, such as:\n",
    "- **Serialization/Deserialization:** Used to handle serialized data transfer between executors.\n",
    "- **JVM Overheads:** Space required for JVM metadata, native memory, etc.\n",
    "- **Task Overheads:** Buffering, intermediate data structures, and OS-level operations.\n",
    "- Configuration:\n",
    "  - Controlled by spark.yarn.executor.memoryOverhead (on YARN) or spark.executor.memoryOverhead:\n",
    "\n",
    "Without sufficient overhead memory, tasks may fail, causing executor OOM errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d64e0f4e-87bb-4a9e-bdac-f24b90a3d615",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c87b2513-eb3f-4c6f-95f6-3c6e483485f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### When do we get executor OOM?\n",
    "Executor OOM errors typically occur under the following conditions:\n",
    "- Insufficient Memory Allocation:\n",
    "  - Executor memory is smaller than required for task execution or caching.\n",
    "- Large Shuffle Data:\n",
    "  - Excessive data in shuffle spills can exceed memory limits.\n",
    "- Improper Partitioning:\n",
    "  - Too few partitions lead to large data chunks in a single task, overwhelming memory.\n",
    "- Caching Large Data:\n",
    "  - When attempting to persist or cache large RDDs/DataFrames with insufficient storage memory.\n",
    "- Broadcast Variables:\n",
    "  - Overly large broadcast variables can exhaust executor memory.\n",
    "- Insufficient Overhead Memory:\n",
    "  - Overhead memory isn’t enough for OS and JVM operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb7305d4-feef-41bc-bded-e070d8f30a60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37af1576-a98e-4da2-9d94-9cd4e9cb2dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Types of Memory Manager in Spark\n",
    "Spark has two types of memory management systems:\n",
    "\n",
    "##### a) Static Memory Manager (Spark 1.5 and earlier)\n",
    "- Fixed allocation for execution and storage memory.\n",
    "- Poor utilization as memory is statically divided.\n",
    "##### b) Unified Memory Manager (Default since Spark 1.6)\n",
    "- Dynamic Allocation:\n",
    "  - Execution and storage memory share a unified pool.\n",
    "  - Unused memory in one area can be used by the other"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "executor_memory_spark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
